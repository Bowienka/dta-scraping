import streamlit as st
from presentations.beautifulsoup import get_slides

import bs4

st.title("BeautifulSoup - Parsov치n칤 HTML v Pythonu")

presentation, text, samples, examples = st.tabs(["Prezentace", "Studijn칤 text", "Uk치zky", "P콏칤klady"])

with presentation:
    get_slides()

with text:
    st.header("Co je BeautifulSoup?")
    st.write("""
    BeautifulSoup je Python knihovna, kter치 usnad켿uje extrakci dat z HTML a XML soubor콢. 
    Poskytuje jednoduch칠 metody pro proch치zen칤, vyhled치v치n칤 a modifikaci parsovan칠ho dokumentu.
    N치zev knihovny je inspirov치n tagem `<soup>` z popul치rn칤ho HTML editoru z roku 1996.
    """)

    st.header("Instalace a z치kladn칤 pou쬴t칤")
    st.code("""
    # Instalace
    pip install beautifulsoup4

    # Z치kladn칤 pou쬴t칤
    from bs4 import BeautifulSoup

    # Vytvo콏en칤 soup objektu
    soup = BeautifulSoup(html_doc, 'html.parser')
    """, language="python")

    st.header("Hlavn칤 funkce BeautifulSoup")
    st.markdown("""
    游댌 **Vyhled치v치n칤 element콢**
    - `find()` - najde prvn칤 v칳skyt elementu
    - `find_all()` - najde v코echny v칳skyty element콢
    - `select()` - vyhled치v치n칤 pomoc칤 CSS selektor콢

    游꺕 **Navigace v dokumentu**
    - `parent` - rodi캜ovsk칳 element
    - `children` - p콏칤m칤 potomci
    - `descendants` - v코ichni potomci
    - `next_sibling` / `previous_sibling` - sousedn칤 elementy

    游닇 **Pr치ce s obsahem**
    - `text` - z칤sk치n칤 textov칠ho obsahu
    - `string` - p콏칤m칳 textov칳 obsah
    - `attrs` - pr치ce s atributy
    """)

    st.header("Praktick칠 p콏칤klady")

    st.subheader("1. Z치kladn칤 vyhled치v치n칤")
    st.code("""
    html_doc = '''
    <div class="content">
        <h1>Hlavn칤 nadpis</h1>
        <p class="text">Prvn칤 odstavec</p>
        <p class="text">Druh칳 odstavec</p>
    </div>
    '''

    soup = BeautifulSoup(html_doc, 'html.parser')

    # Naj칤t prvn칤 odstavec
    first_p = soup.find('p')
    print(first_p.text)  # Prvn칤 odstavec

    # Naj칤t v코echny odstavce
    all_p = soup.find_all('p')
    for p in all_p:
        print(p.text)
    """, language="python")

    st.subheader("2. CSS selektory")
    st.code("""
    # Naj칤t elementy podle t콏칤dy
    text_elements = soup.select('.text')

    # Naj칤t element uvnit콏 jin칠ho
    content_h1 = soup.select('.content h1')
    """, language="python")

    st.subheader("3. Pr치ce s atributy")
    st.code("""
    # Z칤sk치n칤 hodnoty atributu
    element = soup.find('p')
    class_name = element['class']

    # Modifikace atributu
    element['class'] = 'new-class'

    # P콏id치n칤 nov칠ho atributu
    element['id'] = 'my-paragraph'
    """, language="python")

    st.header("Pokro캜il칠 techniky")
    st.write("""
    BeautifulSoup nab칤z칤 n캩kolik pokro캜il칳ch funkc칤 pro slo쬴t캩j코칤 sc칠n치콏e:
    """)

    st.code("""
    # Vlastn칤 filtrovac칤 funkce
    def has_class_but_no_id(tag):
        return tag.has_attr('class') and not tag.has_attr('id')

    soup.find_all(has_class_but_no_id)

    # Regul치rn칤 v칳razy
    import re
    soup.find_all(text=re.compile("odstavec"))

    # Rekurzivn칤 vyhled치v치n칤
    soup.find_all('p', recursive=True)
    """, language="python")

    st.info("""
    游눠 **Tip**: Pro lep코칤 v칳kon p콏i parsov치n칤 velk칳ch dokument콢 pou쬴jte parser 'lxml':
    ```python
    soup = BeautifulSoup(html_doc, 'lxml')
    ```
    Nejprve je pot콏eba nainstalovat lxml: `pip install lxml`
    """)

    st.warning("""
    丘멆잺 **캛ast칠 probl칠my**:
    1. **K칩dov치n칤** - ujist캩te se, 쬰 pou쮂셨치te spr치vn칠 k칩dov치n칤 p콏i 캜ten칤 HTML
    2. **None hodnoty** - v쬯y kontrolujte, zda element existuje
    3. **Dynamick칳 obsah** - BeautifulSoup neparsuje JavaScript, pro dynamick칳 obsah pou쬴jte Selenium
    4. **V칳kon** - pro velk칠 dokumenty zva쬾e pou쬴t칤 lxml parseru nebo CSS selektor콢
    """)

    st.header("U쬴te캜n칠 zdroje")
    st.markdown("""
    - [Ofici치ln칤 dokumentace BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
    - [Tutori치l na Real Python](https://realpython.com/beautiful-soup-web-scraper-python/)
    - [Praktick칠 p콏칤klady na GitHub](https://github.com/topics)""")

with samples:
    import streamlit as st
    import requests
    from bs4 import BeautifulSoup

    st.title("Interaktivn칤 uk치zky BeautifulSoup")

    st.header("1. Z치kladn칤 extrakce dat")
    with st.expander("Jednoduch칳 p콏칤klad extrakce"):
        st.subheader("Vstupn칤 HTML")
        html_input = st.text_area(
            "HTML k칩d",
            '''
<div class="product">
    <h2>iPhone 14</h2>
    <p class="price">24 990 K캜</p>
    <span class="stock">Skladem</span>
</div>
            ''',
            height=200
        )

        st.subheader("Python k칩d")
        st.code("""
    from bs4 import BeautifulSoup

    soup = BeautifulSoup(html_input, 'html.parser')
    product = soup.find('div', class_='product')

    nazev = product.h2.text
    cena = product.find('p', class_='price').text
    sklad = product.find('span', class_='stock').text

    print(f"N치zev: {nazev}")
    print(f"Cena: {cena}")
    print(f"Dostupnost: {sklad}")
            """, language="python")

        if st.button("Spustit extrakci", key="basic_extraction"):
            soup = BeautifulSoup(html_input, 'html.parser')
            try:
                product = soup.find('div', class_='product')
                nazev = product.h2.text
                cena = product.find('p', class_='price').text
                sklad = product.find('span', class_='stock').text

                st.success(f"""
                    V칳sledek extrakce:
                    - N치zev: {nazev}
                    - Cena: {cena}
                    - Dostupnost: {sklad}
                    """)
            except Exception as e:
                st.error(f"Chyba p콏i extrakci: {str(e)}")

    st.header("2. Vyhled치v치n칤 pomoc칤 r콢zn칳ch metod")
    with st.expander("Porovn치n칤 metod vyhled치v치n칤"):
        html_complex = """
            <div class="container">
                <article class="post">
                    <h2>Prvn칤 캜l치nek</h2>
                    <p class="text">Text prvn칤ho 캜l치nku</p>
                    <a href="link1.html">캛칤st v칤ce</a>
                </article>
                <article class="post featured">
                    <h2>Druh칳 캜l치nek</h2>
                    <p class="text">Text druh칠ho 캜l치nku</p>
                    <a href="link2.html">캛칤st v칤ce</a>
                </article>
            </div>
            """

        st.code(html_complex, language="html")

        method = st.selectbox(
            "Vyberte metodu vyhled치v치n칤",
            ["find()", "find_all()", "select()", "select_one()"]
        )

        if method == "find()":
            st.code("""
        soup = BeautifulSoup(html_complex, 'html.parser')
        prvni_clanek = soup.find('article')
        print(prvni_clanek.h2.text)
                """, language="python")

            if st.button("Spustit find()"):
                soup = BeautifulSoup(html_complex, 'html.parser')
                prvni_clanek = soup.find('article')
                st.write(f"Nalezen 캜l치nek: {prvni_clanek.h2.text}")

        elif method == "find_all()":
            st.code("""
        soup = BeautifulSoup(html_complex, 'html.parser')
        clanky = soup.find_all('article')
        for clanek in clanky:
            print(clanek.h2.text)
                """, language="python")

            if st.button("Spustit find_all()"):
                soup = BeautifulSoup(html_complex, 'html.parser')
                clanky = soup.find_all('article')
                for clanek in clanky:
                    st.write(f"Nalezen 캜l치nek: {clanek.h2.text}")

        elif method == "select()":
            st.code("""
        soup = BeautifulSoup(html_complex, 'html.parser')
        featured = soup.select('article.featured')
        for clanek in featured:
            print(clanek.h2.text)
                """, language="python")

            if st.button("Spustit select()"):
                soup = BeautifulSoup(html_complex, 'html.parser')
                featured = soup.select('article.featured')
                for clanek in featured:
                    st.write(f"Nalezen zv칳razn캩n칳 캜l치nek: {clanek.h2.text}")

        elif method == "select_one()":
            st.code("""
        soup = BeautifulSoup(html_complex, 'html.parser')
        prvni = soup.select_one('article.post')
        print(prvni.h2.text)
                """, language="python")

            if st.button("Spustit select_one()"):
                soup = BeautifulSoup(html_complex, 'html.parser')
                prvni = soup.select_one('article.post')
                st.write(f"Nalezen prvn칤 캜l치nek: {prvni.h2.text}")

    st.header("3. Navigace v DOM")
    with st.expander("Uk치zka navigace"):
        html_nav = '''
            <div class="wrapper">
                <header>
                    <h1>Hlavn칤 nadpis</h1>
                    <nav>
                        <ul>
                            <li>Prvn칤</li>
                            <li>Druh칳</li>
                            <li>T콏et칤</li>
                        </ul>
                    </nav>
                </header>
                <main>
                    <p>Hlavn칤 obsah</p>
                </main>
            </div>
            '''

        st.code(html_nav, language="html")

        nav_method = st.selectbox(
            "Vyberte zp콢sob navigace",
            ["parent", "children", "next_sibling", "previous_sibling"]
        )

        if nav_method == "parent":
            st.code("""
        soup = BeautifulSoup(html_nav, 'html.parser')
        li = soup.find('li')
        parent_ul = li.parent
        parent_nav = parent_ul.parent
        print(f"Rodi캜 <li>: {parent_ul.name}")
        print(f"Rodi캜 <ul>: {parent_nav.name}")
                """, language="python")

            if st.button("Zobrazit rodi캜e"):
                soup = BeautifulSoup(html_nav, 'html.parser')
                li = soup.find('li')
                parent_ul = li.parent
                parent_nav = parent_ul.parent
                st.write(f"Rodi캜 <li>: {parent_ul.name}")
                st.write(f"Rodi캜 <ul>: {parent_nav.name}")

        elif nav_method == "children":
            st.code("""
        soup = BeautifulSoup(html_nav, 'html.parser')
        nav = soup.find('nav')
        for child in nav.children:
            if child.name:
                print(f"Potomek <nav>: {child.name}")
                """, language="python")

            if st.button("Zobrazit potomky"):
                soup = BeautifulSoup(html_nav, 'html.parser')
                nav = soup.find('nav')
                for child in nav.children:
                    if child.name:
                        st.write(f"Potomek <nav>: {child.name}")

        elif nav_method == "next_sibling":
            st.code("""
        soup = BeautifulSoup(html_nav, 'html.parser')
        header = soup.find('header')
        main = header.next_sibling.next_sibling
        print(f"Po <header> n치sleduje: {main.name}")
                """, language="python")

            if st.button("Zobrazit n치sleduj칤c칤 element"):
                soup = BeautifulSoup(html_nav, 'html.parser')
                header = soup.find('header')
                main = header.next_sibling.next_sibling
                st.write(f"Po <header> n치sleduje: {main.name}")

        elif nav_method == "previous_sibling":
            st.code("""
        soup = BeautifulSoup(html_nav, 'html.parser')
        main = soup.find('main')
        header = main.previous_sibling.previous_sibling
        print(f"P콏ed <main> je: {header.name}")
                """, language="python")

            if st.button("Zobrazit p콏edchoz칤 element"):
                soup = BeautifulSoup(html_nav, 'html.parser')
                main = soup.find('main')
                header = main.previous_sibling.previous_sibling
                st.write(f"P콏ed <main> je: {header.name}")

with examples:
    st.title("Cvi캜en칤 - BeautifulSoup")

    st.info("""
     游눠 **Obecn칠 tipy pro 콏e코en칤 칰kol콢:**
     1. Nejprve si prohl칠dn캩te strukturu HTML
     2. Identifikujte kl칤캜ov칠 elementy a jejich atributy
     3. Zkuste nejprve jednoduch칠 콏e코en칤, potom ho vylep코ujte
     4. Nezapome켿te na o코et콏en칤 chyb
     5. Testujte 콏e코en칤 na r콢zn칳ch vstupech
     """)

    st.warning("""
     丘멆잺 **캛ast치 칰skal칤:**
     1. Chyb캩j칤c칤 elementy
     2. Nekonzistentn칤 struktura
     3. Speci치ln칤 znaky v textu
     4. Nested elementy
     5. Whitespace v textu
     """)

    st.header("칔kol 1: Extrakce produkt콢")
    with st.expander("Zobrazit zad치n칤"):
        st.markdown("""
        Z n치sleduj칤c칤ho HTML k칩du extrahujte informace o v코ech produktech (n치zev, cena, dostupnost):
        """)

        html_products = '''
        <div class="eshop">
            <div class="product">
                <h2>iPhone 14</h2>
                <p class="price">24 990 K캜</p>
                <span class="stock">Skladem</span>
            </div>
            <div class="product">
                <h2>Samsung Galaxy S23</h2>
                <p class="price">21 490 K캜</p>
                <span class="stock">Vyprod치no</span>
            </div>
            <div class="product">
                <h2>Xiaomi 13</h2>
                <p class="price">18 999 K캜</p>
                <span class="stock">Skladem</span>
            </div>
        </div>
        '''

        st.code(html_products, language="html")

        if st.button("Zobrazit n치pov캩du", key="hint1"):
            st.info("""
            1. Pou쬴jte `find_all()` pro nalezen칤 v코ech produkt콢
            2. Pro ka쬯칳 produkt najd캩te jeho elementy pomoc칤:
               - `find('h2')` pro n치zev
               - `find('p', class_='price')` pro cenu
               - `find('span', class_='stock')` pro dostupnost
            3. Pou쬴jte `.text` pro z칤sk치n칤 textu z element콢
            """)

        if st.button("Zobrazit 콏e코en칤", key="solution1"):
            st.code("""
            from bs4 import BeautifulSoup

            soup = BeautifulSoup(html_products, 'html.parser')
            products = soup.find_all('div', class_='product')

            for product in products:
                name = product.find('h2').text
                price = product.find('p', class_='price').text
                stock = product.find('span', class_='stock').text
                print(f"Produkt: {name}, Cena: {price}, Dostupnost: {stock}")
            """, language="python")

    st.header("칔kol 2: Extrakce odkaz콢 z menu")
    with st.expander("Zobrazit zad치n칤"):
        st.markdown("""
        Extrahujte v코echny odkazy z naviga캜n칤ho menu v캜etn캩 jejich URL:
        """)

        html_menu = '''
        <nav class="menu">
            <ul>
                <li><a href="/" class="active">Dom콢</a></li>
                <li><a href="/produkty">Produkty</a></li>
                <li><a href="/kontakt">Kontakt</a>
                    <ul class="submenu">
                        <li><a href="/email">Email</a></li>
                        <li><a href="/telefon">Telefon</a></li>
                    </ul>
                </li>
            </ul>
        </nav>
        '''

        st.code(html_menu, language="html")

        if st.button("Zobrazit n치pov캩du", key="hint2"):
            st.info("""
            1. Najd캩te v코echny odkazy pomoc칤 `find_all('a')`
            2. Pro ka쬯칳 odkaz z칤skejte:
               - Text pomoc칤 `.text`
               - URL pomoc칤 `['href']`
            3. Bonus: Rozli코te hlavn칤 menu a submenu pomoc칤 rodi캜ovsk칳ch element콢
            """)

        if st.button("Zobrazit 콏e코en칤", key="solution2"):
            st.code("""
            from bs4 import BeautifulSoup

            soup = BeautifulSoup(html_menu, 'html.parser')

            # Z치kladn칤 콏e코en칤
            for link in soup.find_all('a'):
                text = link.text
                url = link['href']
                print(f"Odkaz: {text} -> {url}")

            # Pokro캜il칠 콏e코en칤 s rozli코en칤m submenu
            main_menu = soup.select('nav > ul > li > a')
            submenu = soup.select('.submenu a')

            print("Hlavn칤 menu:")
            for link in main_menu:
                print(f"- {link.text}: {link['href']}")

            print("\\nSubmenu:")
            for link in submenu:
                print(f"- {link.text}: {link['href']}")
            """, language="python")

    st.header("칔kol 3: Anal칳za 캜l치nku")
    with st.expander("Zobrazit zad치n칤"):
        st.markdown("""
        Analyzujte strukturu 캜l치nku a extrahujte jeho 캜치sti:
        """)

        html_article = '''
        <article class="blog-post">
            <header>
                <h1>Pr콢vodce Python programov치n칤m</h1>
                <div class="meta">
                    <span class="author">Jan Nov치k</span>
                    <time datetime="2024-03-15">15.3.2024</time>
                    <span class="category">Python</span>
                </div>
            </header>
            <div class="content">
                <p>Prvn칤 odstavec 캜l치nku...</p>
                <h2>Podnadpis</h2>
                <p>Druh칳 odstavec 캜l치nku...</p>
                <ul class="tags">
                    <li>programov치n칤</li>
                    <li>za캜치te캜n칤ci</li>
                    <li>tutorial</li>
                </ul>
            </div>
        </article>
        '''

        st.code(html_article, language="html")

        if st.button("Zobrazit n치pov캩du", key="hint3"):
            st.info("""
            1. Rozd캩lte extrakci na logick칠 캜치sti:
               - Hlavi캜ka (titulek, autor, datum, kategorie)
               - Obsah (odstavce, podnadpisy)
               - Tagy
            2. Pou쬴jte kombinaci metod:
               - `find()` pro jedine캜n칠 elementy
               - `find_all()` pro seznamy
               - `select()` pro slo쬴t캩j코칤 CSS selektory
            """)

        if st.button("Zobrazit 콏e코en칤", key="solution3"):
            st.code("""
            from bs4 import BeautifulSoup

            soup = BeautifulSoup(html_article, 'html.parser')

            # Extrakce hlavi캜ky
            title = soup.h1.text
            author = soup.find('span', class_='author').text
            date = soup.time['datetime']
            category = soup.find('span', class_='category').text

            print(f"Titulek: {title}")
            print(f"Autor: {author}")
            print(f"Datum: {date}")
            print(f"Kategorie: {category}")

            # Extrakce obsahu
            content = soup.find('div', class_='content')
            paragraphs = content.find_all('p')
            subtitles = content.find_all('h2')

            print("\\nObsah:")
            for p in paragraphs:
                print(f"Odstavec: {p.text}")

            # Extrakce tag콢
            tags = soup.select('.tags li')
            print("\\nTagy:")
            for tag in tags:
                print(f"- {tag.text}")
            """, language="python")

    st.header("칔kol 4: Tabulkov치 data")
    with st.expander("Zobrazit zad치n칤"):
        st.markdown("""
        Extrahujte data z tabulky do strukturovan칠 podoby:
        """)

        html_table = '''
        <table class="data-table">
            <thead>
                <tr>
                    <th>Jm칠no</th>
                    <th>V캩k</th>
                    <th>M캩sto</th>
                    <th>Sk칩re</th>
                </tr>
            </thead>
            <tbody>
                <tr class="odd">
                    <td>Anna Mal치</td>
                    <td>25</td>
                    <td>Praha</td>
                    <td>95</td>
                </tr>
                <tr class="even">
                    <td>Petr Velk칳</td>
                    <td>32</td>
                    <td>Brno</td>
                    <td>88</td>
                </tr>
                <tr class="odd">
                    <td>Eva Nov치</td>
                    <td>28</td>
                    <td>Ostrava</td>
                    <td>92</td>
                </tr>
            </tbody>
        </table>
        '''

        st.code(html_table, language="html")

        if st.button("Zobrazit n치pov캩du", key="hint4"):
            st.info("""
            1. Nejprve z칤skejte hlavi캜ky sloupc콢 z `thead`
            2. Pot칠 zpracujte 콏치dky z `tbody`
            3. Pro ka쬯칳 콏치dek z칤skejte hodnoty bun캩k
            4. M콢쬰te data ulo쬴t do:
               - Seznam slovn칤k콢
               - Pandas DataFrame
            5. Bonus: O코et콏ete typy dat (캜칤sla jako int)
            """)

        if st.button("Zobrazit 콏e코en칤", key="solution4"):
            st.code("""
            from bs4 import BeautifulSoup
            import pandas as pd

            soup = BeautifulSoup(html_table, 'html.parser')

            # Z칤sk치n칤 hlavi캜ek
            headers = [th.text for th in soup.find('thead').find_all('th')]

            # Z칤sk치n칤 dat
            data = []
            for row in soup.find('tbody').find_all('tr'):
                row_data = [td.text for td in row.find_all('td')]
                data.append(dict(zip(headers, row_data)))

            # P콏evod na DataFrame
            df = pd.DataFrame(data)

            # Konverze typ콢
            df['V캩k'] = df['V캩k'].astype(int)
            df['Sk칩re'] = df['Sk칩re'].astype(int)

            print(df)
            """, language="python")

